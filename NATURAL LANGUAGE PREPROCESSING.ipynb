{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97bd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d888d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello Mr. VK I am there, how are you doing today? The weather is great and Nltk is awesome. The Nltk is super compare to other library. Its oops based developed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71955dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. VK I am there, how are you doing today?', 'The weather is great and Nltk is awesome.', 'The Nltk is super compare to other library.', 'Its oops based developed.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeac5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'VK', 'I', 'am', 'there', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', 'and', 'Nltk', 'is', 'awesome', '.', 'The', 'Nltk', 'is', 'super', 'compare', 'to', 'other', 'library', '.', 'Its', 'oops', 'based', 'developed', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e5791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Mr.\n",
      "VK\n",
      "I\n",
      "am\n",
      "there\n",
      ",\n",
      "how\n",
      "are\n",
      "you\n",
      "doing\n",
      "today\n",
      "?\n",
      "The\n",
      "weather\n",
      "is\n",
      "great\n",
      "and\n",
      "Nltk\n",
      "is\n",
      "awesome\n",
      ".\n",
      "The\n",
      "Nltk\n",
      "is\n",
      "super\n",
      "compare\n",
      "to\n",
      "other\n",
      "library\n",
      ".\n",
      "Its\n",
      "oops\n",
      "based\n",
      "developed\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in word_tokenize(text):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "708a12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7025188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63875d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wasn', 'myself', 'll', 'no', 'her', \"you'll\", 'weren', 'ours', 'or', 'other', 'down', 'that', 'didn', 'were', \"hasn't\", 'shan', 'don', 'again', 'if', 'yours', 'theirs', 'these', 'it', 'me', 'too', 're', 'their', 'i', 'some', 'on', 'own', 'and', 'doing', \"don't\", 'what', 'y', 'because', \"wasn't\", 'to', 'then', 'doesn', 'why', 'only', 'than', 'o', 'under', 'same', 'been', 'which', 'do', 'by', 'itself', 'for', 'now', 'this', \"didn't\", 'while', \"should've\", 'they', \"haven't\", 'any', 'the', 'until', 'so', 'haven', 'can', 'of', 'above', 'couldn', 'hasn', 'our', 'you', 'from', 'there', 'through', 'him', 'off', 'more', 'yourselves', \"that'll\", 'aren', \"weren't\", 'against', 'wouldn', 'his', 'about', 'who', 'such', 'isn', \"you'd\", 'before', 'most', \"mightn't\", 'its', 's', 'be', 'yourself', 'not', \"won't\", 'will', \"mustn't\", \"doesn't\", 've', 'here', 'over', 'up', 'd', \"isn't\", 'further', 'has', 'all', \"couldn't\", 'she', 'how', 'himself', 'am', 'a', \"she's\", 'hers', 'with', 'mightn', 'won', 'both', 'few', 'ma', 'having', 'should', 'have', 'shouldn', 'once', \"shan't\", 'had', 'very', \"wouldn't\", 'as', 'does', 'at', 'below', 'nor', \"shouldn't\", 'just', \"you've\", \"you're\", 'those', 'but', \"hadn't\", 'was', 'an', 'mustn', 'is', 'out', 'them', \"it's\", 'he', 'ourselves', 'each', 'ain', 'where', 'during', 'being', 'm', 'hadn', \"needn't\", \"aren't\", 'your', 'when', 'into', 'we', 'whom', 'themselves', 't', 'did', 'between', 'in', 'needn', 'after', 'are', 'my', 'herself'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e676a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'VK', 'I', ',', 'today', '?', 'The', 'weather', 'great', 'Nltk', 'awesome', '.', 'The', 'Nltk', 'super', 'compare', 'library', '.', 'Its', 'oops', 'based', 'developed', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "filtered_sentence =[]\n",
    "\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "        \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4c0606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4b2b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "505a3ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "ex_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "\n",
    "for s in ex_words:\n",
    "    print(ps.stem(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12feedd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "is\n",
      "veri\n",
      "import\n",
      "to\n",
      "be\n",
      "pythoniy\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "atleast\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "n_t = \"It is very important to be pythoniy while you are pythoning with python. All pythoners have pythoned poorly atleast once.\"\n",
    "\n",
    "words = word_tokenize(n_t)\n",
    "\n",
    "for st in  words:\n",
    "    print(ps.stem(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2866cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTS OF SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e10db5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efccf7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"Engineers, as practitioners of engineering, are professionals who invent, design, analyze, build and test machines, complex systems, structures, gadgets and materials to fulfill functional objectives and requirements while considering the limitations imposed by practicality, regulation, safety and cost.[1][2] The word engineer (Latin ingeniator[3]) is derived from the Latin words ingeniare (to create, generate, contrive, devise and ingenium) (cleverness).[4][5] The foundational qualifications of an engineer typically include a four-year bachelor's degree in an engineering discipline, or in some jurisdictions, a master's degree in an engineering discipline plus four to six years of peer-reviewed professional practice (culminating in a project report or thesis) and passage of engineering board examinations.The work of engineers forms the link between scientific discoveries and their subsequent applications to human and business needs and quality of life.[1]\"\n",
    "sample_text = \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s. NLP's creators claim there is a connection between neurological processes (neuro-), language (linguistic) and behavioral patterns learned through experience (programming), and that these can be changed to achieve specific goals in life.[1][2]: 2  Bandler and Grinder also claim that NLP methodology can model the skills of exceptional people, allowing anyone to acquire those skills.[3]: 5–6 [4] They claim as well that, often in a single session, NLP can treat problems such as phobias, depression, tic disorders, psychosomatic illnesses, near-sightedness,[5] allergy, the common cold,[Note 1] and learning disorders.[7][8] NLP has been adopted by some hypnotherapists and also by companies that run seminars marketed as leadership training to businesses and government agencies.[9][10]There is no scientific evidence supporting the claims made by NLP advocates, and it has been discredited as a pseudoscience.[11][12][13] Scientific reviews state that NLP is based on outdated metaphors of how the brain works that are inconsistent with current neurological theory and contain numerous factual errors.[10][14] Reviews also found that all of the supportive research on NLP contained significant methodological flaws and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, Grinder, and other NLP practitioners.[12][13]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09d9337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0960fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Neuro-linguistic', 'JJ'), ('programming', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('pseudoscientific', 'JJ'), ('approach', 'NN'), ('to', 'TO'), ('communication', 'NN'), (',', ','), ('personal', 'JJ'), ('development', 'NN'), (',', ','), ('and', 'CC'), ('psychotherapy', 'RB'), ('created', 'VBN'), ('by', 'IN'), ('Richard', 'NNP'), ('Bandler', 'NNP'), ('and', 'CC'), ('John', 'NNP'), ('Grinder', 'NNP'), ('in', 'IN'), ('California', 'NNP'), (',', ','), ('United', 'NNP'), ('States', 'NNPS'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('1970s', 'CD'), ('.', '.')]\n",
      "[('NLP', 'NNP'), (\"'s\", 'POS'), ('creators', 'NNS'), ('claim', 'VBP'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('connection', 'NN'), ('between', 'IN'), ('neurological', 'JJ'), ('processes', 'NNS'), ('(', '('), ('neuro-', 'JJ'), (')', ')'), (',', ','), ('language', 'NN'), ('(', '('), ('linguistic', 'JJ'), (')', ')'), ('and', 'CC'), ('behavioral', 'JJ'), ('patterns', 'NNS'), ('learned', 'VBD'), ('through', 'IN'), ('experience', 'NN'), ('(', '('), ('programming', 'VBG'), (')', ')'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('these', 'DT'), ('can', 'MD'), ('be', 'VB'), ('changed', 'VBN'), ('to', 'TO'), ('achieve', 'VB'), ('specific', 'JJ'), ('goals', 'NNS'), ('in', 'IN'), ('life', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('1', 'CD'), (']', 'JJ'), ('[', '$'), ('2', 'CD'), (']', 'NN'), (':', ':'), ('2', 'CD'), ('Bandler', 'NNP'), ('and', 'CC'), ('Grinder', 'NNP'), ('also', 'RB'), ('claim', 'VBP'), ('that', 'IN'), ('NLP', 'NNP'), ('methodology', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('skills', 'NNS'), ('of', 'IN'), ('exceptional', 'JJ'), ('people', 'NNS'), (',', ','), ('allowing', 'VBG'), ('anyone', 'NN'), ('to', 'TO'), ('acquire', 'VB'), ('those', 'DT'), ('skills', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('3', 'CD'), (']', 'NNS'), (':', ':'), ('5–6', 'CD'), ('[', '$'), ('4', 'CD'), (']', 'NN'), ('They', 'PRP'), ('claim', 'VBP'), ('as', 'RB'), ('well', 'RB'), ('that', 'IN'), (',', ','), ('often', 'RB'), ('in', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('session', 'NN'), (',', ','), ('NLP', 'NNP'), ('can', 'MD'), ('treat', 'VB'), ('problems', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('phobias', 'NNS'), (',', ','), ('depression', 'NN'), (',', ','), ('tic', 'JJ'), ('disorders', 'NNS'), (',', ','), ('psychosomatic', 'JJ'), ('illnesses', 'NNS'), (',', ','), ('near-sightedness', 'JJ'), (',', ','), ('[', 'JJ'), ('5', 'CD'), (']', 'NN'), ('allergy', 'NN'), (',', ','), ('the', 'DT'), ('common', 'JJ'), ('cold', 'NN'), (',', ','), ('[', 'NNP'), ('Note', 'NNP'), ('1', 'CD'), (']', 'NN'), ('and', 'CC'), ('learning', 'NN'), ('disorders', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('[', '$'), ('8', 'CD'), (']', 'NNP'), ('NLP', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('adopted', 'VBN'), ('by', 'IN'), ('some', 'DT'), ('hypnotherapists', 'NNS'), ('and', 'CC'), ('also', 'RB'), ('by', 'IN'), ('companies', 'NNS'), ('that', 'WDT'), ('run', 'VBP'), ('seminars', 'RB'), ('marketed', 'VBN'), ('as', 'IN'), ('leadership', 'NN'), ('training', 'NN'), ('to', 'TO'), ('businesses', 'NNS'), ('and', 'CC'), ('government', 'NN'), ('agencies', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('9', 'CD'), (']', 'JJ'), ('[', '$'), ('10', 'CD'), (']', 'NN'), ('There', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('scientific', 'JJ'), ('evidence', 'NN'), ('supporting', 'VBG'), ('the', 'DT'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('NLP', 'NNP'), ('advocates', 'NNS'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('been', 'VBN'), ('discredited', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('pseudoscience', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('[', '$'), ('12', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('13', 'CD'), (']', 'NNP'), ('Scientific', 'NNP'), ('reviews', 'VBZ'), ('state', 'NN'), ('that', 'IN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('outdated', 'JJ'), ('metaphors', 'NNS'), ('of', 'IN'), ('how', 'WRB'), ('the', 'DT'), ('brain', 'NN'), ('works', 'VBZ'), ('that', 'WDT'), ('are', 'VBP'), ('inconsistent', 'JJ'), ('with', 'IN'), ('current', 'JJ'), ('neurological', 'JJ'), ('theory', 'NN'), ('and', 'CC'), ('contain', 'VBP'), ('numerous', 'JJ'), ('factual', 'JJ'), ('errors', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('[', '$'), ('14', 'CD'), (']', 'NNP'), ('Reviews', 'NNP'), ('also', 'RB'), ('found', 'VBD'), ('that', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('supportive', 'JJ'), ('research', 'NN'), ('on', 'IN'), ('NLP', 'NNP'), ('contained', 'VBD'), ('significant', 'JJ'), ('methodological', 'JJ'), ('flaws', 'NNS'), ('and', 'CC'), ('that', 'IN'), ('there', 'EX'), ('were', 'VBD'), ('three', 'CD'), ('times', 'NNS'), ('as', 'IN'), ('many', 'JJ'), ('studies', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('much', 'JJ'), ('higher', 'JJR'), ('quality', 'NN'), ('that', 'WDT'), ('failed', 'VBD'), ('to', 'TO'), ('reproduce', 'VB'), ('the', 'DT'), ('extraordinary', 'JJ'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('Bandler', 'NNP'), (',', ','), ('Grinder', 'NNP'), (',', ','), ('and', 'CC'), ('other', 'JJ'), ('NLP', 'NNP'), ('practitioners', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('12', 'CD'), (']', 'JJ'), ('[', '$'), ('13', 'CD'), (']', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "500a7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGULAR EXPRESSIONS USED TO REMOVE NOISY CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27e7b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Neuro-linguistic/JJ\n",
      "  programming/NN\n",
      "  (/(\n",
      "  (Chunk NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pseudoscientific/JJ\n",
      "  approach/NN\n",
      "  to/TO\n",
      "  communication/NN\n",
      "  ,/,\n",
      "  personal/JJ\n",
      "  development/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  psychotherapy/RB\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (Chunk Richard/NNP Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (Chunk California/NNP)\n",
      "  ,/,\n",
      "  (Chunk United/NNP)\n",
      "  States/NNPS\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk NLP/NNP)\n",
      "  's/POS\n",
      "  creators/NNS\n",
      "  claim/VBP\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  connection/NN\n",
      "  between/IN\n",
      "  neurological/JJ\n",
      "  processes/NNS\n",
      "  (/(\n",
      "  neuro-/JJ\n",
      "  )/)\n",
      "  ,/,\n",
      "  language/NN\n",
      "  (/(\n",
      "  linguistic/JJ\n",
      "  )/)\n",
      "  and/CC\n",
      "  behavioral/JJ\n",
      "  patterns/NNS\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  experience/NN\n",
      "  (/(\n",
      "  programming/VBG\n",
      "  )/)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  these/DT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  specific/JJ\n",
      "  goals/NNS\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  1/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  2/CD\n",
      "  ]/NN\n",
      "  :/:\n",
      "  2/CD\n",
      "  (Chunk Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk Grinder/NNP)\n",
      "  also/RB\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP methodology/NN)\n",
      "  can/MD\n",
      "  model/VB\n",
      "  the/DT\n",
      "  skills/NNS\n",
      "  of/IN\n",
      "  exceptional/JJ\n",
      "  people/NNS\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  anyone/NN\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  skills/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/NNS\n",
      "  :/:\n",
      "  5–6/CD\n",
      "  [/$\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  claim/VBP\n",
      "  as/RB\n",
      "  well/RB\n",
      "  that/IN\n",
      "  ,/,\n",
      "  often/RB\n",
      "  in/IN\n",
      "  a/DT\n",
      "  single/JJ\n",
      "  session/NN\n",
      "  ,/,\n",
      "  (Chunk NLP/NNP)\n",
      "  can/MD\n",
      "  treat/VB\n",
      "  problems/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  phobias/NNS\n",
      "  ,/,\n",
      "  depression/NN\n",
      "  ,/,\n",
      "  tic/JJ\n",
      "  disorders/NNS\n",
      "  ,/,\n",
      "  psychosomatic/JJ\n",
      "  illnesses/NNS\n",
      "  ,/,\n",
      "  near-sightedness/JJ\n",
      "  ,/,\n",
      "  [/JJ\n",
      "  5/CD\n",
      "  ]/NN\n",
      "  allergy/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  common/JJ\n",
      "  cold/NN\n",
      "  ,/,\n",
      "  (Chunk [/NNP Note/NNP)\n",
      "  1/CD\n",
      "  ]/NN\n",
      "  and/CC\n",
      "  learning/NN\n",
      "  disorders/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  7/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  8/CD\n",
      "  (Chunk ]/NNP NLP/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  hypnotherapists/NNS\n",
      "  and/CC\n",
      "  also/RB\n",
      "  by/IN\n",
      "  companies/NNS\n",
      "  that/WDT\n",
      "  run/VBP\n",
      "  seminars/RB\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  leadership/NN\n",
      "  training/NN\n",
      "  to/TO\n",
      "  businesses/NNS\n",
      "  and/CC\n",
      "  government/NN\n",
      "  agencies/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  9/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  10/CD\n",
      "  ]/NN\n",
      "  There/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  scientific/JJ\n",
      "  evidence/NN\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  advocates/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  pseudoscience/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  11/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  12/CD\n",
      "  (Chunk ]/NNP)\n",
      "  [/VBD\n",
      "  13/CD\n",
      "  (Chunk ]/NNP Scientific/NNP)\n",
      "  reviews/VBZ\n",
      "  state/NN\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  outdated/JJ\n",
      "  metaphors/NNS\n",
      "  of/IN\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  brain/NN\n",
      "  works/VBZ\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  inconsistent/JJ\n",
      "  with/IN\n",
      "  current/JJ\n",
      "  neurological/JJ\n",
      "  theory/NN\n",
      "  and/CC\n",
      "  contain/VBP\n",
      "  numerous/JJ\n",
      "  factual/JJ\n",
      "  errors/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  10/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  14/CD\n",
      "  (Chunk ]/NNP Reviews/NNP)\n",
      "  also/RB\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  supportive/JJ\n",
      "  research/NN\n",
      "  on/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  contained/VBD\n",
      "  significant/JJ\n",
      "  methodological/JJ\n",
      "  flaws/NNS\n",
      "  and/CC\n",
      "  that/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  three/CD\n",
      "  times/NNS\n",
      "  as/IN\n",
      "  many/JJ\n",
      "  studies/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  much/JJ\n",
      "  higher/JJR\n",
      "  quality/NN\n",
      "  that/WDT\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  extraordinary/JJ\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk Bandler/NNP)\n",
      "  ,/,\n",
      "  (Chunk Grinder/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  (Chunk NLP/NNP)\n",
      "  practitioners/NNS\n",
      "  ./.)\n",
      "(S [/RB 12/CD ]/JJ [/$ 13/CD ]/NN)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" \n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            print(chunked)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ec36077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHINKING IT IS SIMILAR TO CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6acb50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk Neuro-linguistic/JJ programming/NN (/( NLP/NNP )/))\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  (Chunk pseudoscientific/JJ approach/NN)\n",
      "  to/TO\n",
      "  (Chunk\n",
      "    communication/NN\n",
      "    ,/,\n",
      "    personal/JJ\n",
      "    development/NN\n",
      "    ,/,\n",
      "    and/CC\n",
      "    psychotherapy/RB)\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (Chunk Richard/NNP Bandler/NNP and/CC John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (Chunk California/NNP ,/, United/NNP States/NNPS ,/,)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (Chunk 1970s/CD ./.))\n",
      "(S\n",
      "  (Chunk NLP/NNP 's/POS creators/NNS)\n",
      "  claim/VBP\n",
      "  (Chunk there/EX)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  (Chunk connection/NN)\n",
      "  between/IN\n",
      "  (Chunk\n",
      "    neurological/JJ\n",
      "    processes/NNS\n",
      "    (/(\n",
      "    neuro-/JJ\n",
      "    )/)\n",
      "    ,/,\n",
      "    language/NN\n",
      "    (/(\n",
      "    linguistic/JJ\n",
      "    )/)\n",
      "    and/CC\n",
      "    behavioral/JJ\n",
      "    patterns/NNS)\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  (Chunk experience/NN (/()\n",
      "  programming/VBG\n",
      "  (Chunk )/) ,/, and/CC)\n",
      "  that/IN\n",
      "  these/DT\n",
      "  (Chunk can/MD)\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  (Chunk specific/JJ goals/NNS)\n",
      "  in/IN\n",
      "  (Chunk life/NN ./.))\n",
      "(S\n",
      "  (Chunk\n",
      "    [/RB\n",
      "    1/CD\n",
      "    ]/JJ\n",
      "    [/$\n",
      "    2/CD\n",
      "    ]/NN\n",
      "    :/:\n",
      "    2/CD\n",
      "    Bandler/NNP\n",
      "    and/CC\n",
      "    Grinder/NNP\n",
      "    also/RB)\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP methodology/NN can/MD)\n",
      "  model/VB\n",
      "  the/DT\n",
      "  (Chunk skills/NNS)\n",
      "  of/IN\n",
      "  (Chunk exceptional/JJ people/NNS ,/,)\n",
      "  allowing/VBG\n",
      "  (Chunk anyone/NN)\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  (Chunk skills/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 3/CD ]/NNS :/: 5–6/CD [/$ 4/CD ]/NN They/PRP)\n",
      "  claim/VBP\n",
      "  (Chunk as/RB well/RB)\n",
      "  that/IN\n",
      "  (Chunk ,/, often/RB)\n",
      "  in/IN\n",
      "  a/DT\n",
      "  (Chunk single/JJ session/NN ,/, NLP/NNP can/MD)\n",
      "  treat/VB\n",
      "  (Chunk problems/NNS such/JJ)\n",
      "  as/IN\n",
      "  (Chunk\n",
      "    phobias/NNS\n",
      "    ,/,\n",
      "    depression/NN\n",
      "    ,/,\n",
      "    tic/JJ\n",
      "    disorders/NNS\n",
      "    ,/,\n",
      "    psychosomatic/JJ\n",
      "    illnesses/NNS\n",
      "    ,/,\n",
      "    near-sightedness/JJ\n",
      "    ,/,\n",
      "    [/JJ\n",
      "    5/CD\n",
      "    ]/NN\n",
      "    allergy/NN\n",
      "    ,/,)\n",
      "  the/DT\n",
      "  (Chunk\n",
      "    common/JJ\n",
      "    cold/NN\n",
      "    ,/,\n",
      "    [/NNP\n",
      "    Note/NNP\n",
      "    1/CD\n",
      "    ]/NN\n",
      "    and/CC\n",
      "    learning/NN\n",
      "    disorders/NNS\n",
      "    ./.))\n",
      "(S\n",
      "  (Chunk [/RB 7/CD ]/JJ [/$ 8/CD ]/NNP NLP/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  (Chunk hypnotherapists/NNS and/CC also/RB)\n",
      "  by/IN\n",
      "  (Chunk companies/NNS that/WDT)\n",
      "  run/VBP\n",
      "  (Chunk seminars/RB)\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  (Chunk leadership/NN training/NN)\n",
      "  to/TO\n",
      "  (Chunk businesses/NNS and/CC government/NN agencies/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 9/CD ]/JJ [/$ 10/CD ]/NN There/EX)\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  (Chunk scientific/JJ evidence/NN)\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  (Chunk claims/NNS)\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk NLP/NNP advocates/NNS ,/, and/CC it/PRP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  (Chunk pseudoscience/NN ./.))\n",
      "(S\n",
      "  (Chunk [/RB 11/CD ]/JJ [/$ 12/CD ]/NNP)\n",
      "  [/VBD\n",
      "  (Chunk 13/CD ]/NNP Scientific/NNP)\n",
      "  reviews/VBZ\n",
      "  (Chunk state/NN)\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  (Chunk outdated/JJ metaphors/NNS)\n",
      "  of/IN\n",
      "  (Chunk how/WRB)\n",
      "  the/DT\n",
      "  (Chunk brain/NN)\n",
      "  works/VBZ\n",
      "  (Chunk that/WDT)\n",
      "  are/VBP\n",
      "  (Chunk inconsistent/JJ)\n",
      "  with/IN\n",
      "  (Chunk current/JJ neurological/JJ theory/NN and/CC)\n",
      "  contain/VBP\n",
      "  (Chunk numerous/JJ factual/JJ errors/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 10/CD ]/JJ [/$ 14/CD ]/NNP Reviews/NNP also/RB)\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk supportive/JJ research/NN)\n",
      "  on/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  contained/VBD\n",
      "  (Chunk significant/JJ methodological/JJ flaws/NNS and/CC)\n",
      "  that/IN\n",
      "  (Chunk there/EX)\n",
      "  were/VBD\n",
      "  (Chunk three/CD times/NNS)\n",
      "  as/IN\n",
      "  (Chunk many/JJ studies/NNS)\n",
      "  of/IN\n",
      "  a/DT\n",
      "  (Chunk much/JJ higher/JJR quality/NN that/WDT)\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  (Chunk extraordinary/JJ claims/NNS)\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk\n",
      "    Bandler/NNP\n",
      "    ,/,\n",
      "    Grinder/NNP\n",
      "    ,/,\n",
      "    and/CC\n",
      "    other/JJ\n",
      "    NLP/NNP\n",
      "    practitioners/NNS\n",
      "    ./.))\n",
      "(S (Chunk [/RB 12/CD ]/JJ [/$ 13/CD ]/NN))\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            print(chunked)\n",
    "            #chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06e6f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME ENTITY RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6108ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go and watch the output like name entity recognition e.g., organization(NNP/NN),....\n",
      "\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  Neuro-linguistic/JJ\n",
      "  programming/NN\n",
      "  (/(\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pseudoscientific/JJ\n",
      "  approach/NN\n",
      "  to/TO\n",
      "  communication/NN\n",
      "  ,/,\n",
      "  personal/JJ\n",
      "  development/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  psychotherapy/RB\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (PERSON Richard/NNP Bandler/NNP)\n",
      "  and/CC\n",
      "  (PERSON John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  ,/,\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  Neuro-linguistic/JJ\n",
      "  programming/NN\n",
      "  (/(\n",
      "  (NE NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pseudoscientific/JJ\n",
      "  approach/NN\n",
      "  to/TO\n",
      "  communication/NN\n",
      "  ,/,\n",
      "  personal/JJ\n",
      "  development/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  psychotherapy/RB\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (NE Richard/NNP Bandler/NNP)\n",
      "  and/CC\n",
      "  (NE John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (NE California/NNP)\n",
      "  ,/,\n",
      "  (NE United/NNP States/NNPS)\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  's/POS\n",
      "  creators/NNS\n",
      "  claim/VBP\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  connection/NN\n",
      "  between/IN\n",
      "  neurological/JJ\n",
      "  processes/NNS\n",
      "  (/(\n",
      "  neuro-/JJ\n",
      "  )/)\n",
      "  ,/,\n",
      "  language/NN\n",
      "  (/(\n",
      "  linguistic/JJ\n",
      "  )/)\n",
      "  and/CC\n",
      "  behavioral/JJ\n",
      "  patterns/NNS\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  experience/NN\n",
      "  (/(\n",
      "  programming/VBG\n",
      "  )/)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  these/DT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  specific/JJ\n",
      "  goals/NNS\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  (NE NLP/NNP)\n",
      "  's/POS\n",
      "  creators/NNS\n",
      "  claim/VBP\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  connection/NN\n",
      "  between/IN\n",
      "  neurological/JJ\n",
      "  processes/NNS\n",
      "  (/(\n",
      "  neuro-/JJ\n",
      "  )/)\n",
      "  ,/,\n",
      "  language/NN\n",
      "  (/(\n",
      "  linguistic/JJ\n",
      "  )/)\n",
      "  and/CC\n",
      "  behavioral/JJ\n",
      "  patterns/NNS\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  experience/NN\n",
      "  (/(\n",
      "  programming/VBG\n",
      "  )/)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  these/DT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  specific/JJ\n",
      "  goals/NNS\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  1/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  2/CD\n",
      "  ]/NN\n",
      "  :/:\n",
      "  2/CD\n",
      "  (PERSON Bandler/NNP)\n",
      "  and/CC\n",
      "  (PERSON Grinder/NNP)\n",
      "  also/RB\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  methodology/NN\n",
      "  can/MD\n",
      "  model/VB\n",
      "  the/DT\n",
      "  skills/NNS\n",
      "  of/IN\n",
      "  exceptional/JJ\n",
      "  people/NNS\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  anyone/NN\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  skills/NNS\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  1/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  2/CD\n",
      "  ]/NN\n",
      "  :/:\n",
      "  2/CD\n",
      "  Bandler/NNP\n",
      "  and/CC\n",
      "  (NE Grinder/NNP)\n",
      "  also/RB\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (NE NLP/NNP)\n",
      "  methodology/NN\n",
      "  can/MD\n",
      "  model/VB\n",
      "  the/DT\n",
      "  skills/NNS\n",
      "  of/IN\n",
      "  exceptional/JJ\n",
      "  people/NNS\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  anyone/NN\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  skills/NNS\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/NNS\n",
      "  :/:\n",
      "  5–6/CD\n",
      "  [/$\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  claim/VBP\n",
      "  as/RB\n",
      "  well/RB\n",
      "  that/IN\n",
      "  ,/,\n",
      "  often/RB\n",
      "  in/IN\n",
      "  a/DT\n",
      "  single/JJ\n",
      "  session/NN\n",
      "  ,/,\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  can/MD\n",
      "  treat/VB\n",
      "  problems/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  phobias/NNS\n",
      "  ,/,\n",
      "  depression/NN\n",
      "  ,/,\n",
      "  tic/JJ\n",
      "  disorders/NNS\n",
      "  ,/,\n",
      "  psychosomatic/JJ\n",
      "  illnesses/NNS\n",
      "  ,/,\n",
      "  near-sightedness/JJ\n",
      "  ,/,\n",
      "  [/JJ\n",
      "  5/CD\n",
      "  ]/NN\n",
      "  allergy/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  common/JJ\n",
      "  cold/NN\n",
      "  ,/,\n",
      "  [/NNP\n",
      "  Note/NNP\n",
      "  1/CD\n",
      "  ]/NN\n",
      "  and/CC\n",
      "  learning/NN\n",
      "  disorders/NNS\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/NNS\n",
      "  :/:\n",
      "  5–6/CD\n",
      "  [/$\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  claim/VBP\n",
      "  as/RB\n",
      "  well/RB\n",
      "  that/IN\n",
      "  ,/,\n",
      "  often/RB\n",
      "  in/IN\n",
      "  a/DT\n",
      "  single/JJ\n",
      "  session/NN\n",
      "  ,/,\n",
      "  (NE NLP/NNP)\n",
      "  can/MD\n",
      "  treat/VB\n",
      "  problems/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  phobias/NNS\n",
      "  ,/,\n",
      "  depression/NN\n",
      "  ,/,\n",
      "  tic/JJ\n",
      "  disorders/NNS\n",
      "  ,/,\n",
      "  psychosomatic/JJ\n",
      "  illnesses/NNS\n",
      "  ,/,\n",
      "  near-sightedness/JJ\n",
      "  ,/,\n",
      "  [/JJ\n",
      "  5/CD\n",
      "  ]/NN\n",
      "  allergy/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  common/JJ\n",
      "  cold/NN\n",
      "  ,/,\n",
      "  [/NNP\n",
      "  Note/NNP\n",
      "  1/CD\n",
      "  ]/NN\n",
      "  and/CC\n",
      "  learning/NN\n",
      "  disorders/NNS\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  7/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  8/CD\n",
      "  ]/NNP\n",
      "  NLP/NNP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  hypnotherapists/NNS\n",
      "  and/CC\n",
      "  also/RB\n",
      "  by/IN\n",
      "  companies/NNS\n",
      "  that/WDT\n",
      "  run/VBP\n",
      "  seminars/RB\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  leadership/NN\n",
      "  training/NN\n",
      "  to/TO\n",
      "  businesses/NNS\n",
      "  and/CC\n",
      "  government/NN\n",
      "  agencies/NNS\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  7/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  8/CD\n",
      "  ]/NNP\n",
      "  NLP/NNP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  hypnotherapists/NNS\n",
      "  and/CC\n",
      "  also/RB\n",
      "  by/IN\n",
      "  companies/NNS\n",
      "  that/WDT\n",
      "  run/VBP\n",
      "  seminars/RB\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  leadership/NN\n",
      "  training/NN\n",
      "  to/TO\n",
      "  businesses/NNS\n",
      "  and/CC\n",
      "  government/NN\n",
      "  agencies/NNS\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  9/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  10/CD\n",
      "  ]/NN\n",
      "  There/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  scientific/JJ\n",
      "  evidence/NN\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  advocates/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  pseudoscience/NN\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  9/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  10/CD\n",
      "  ]/NN\n",
      "  There/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  scientific/JJ\n",
      "  evidence/NN\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (NE NLP/NNP)\n",
      "  advocates/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  pseudoscience/NN\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  11/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  12/CD\n",
      "  ]/NNP\n",
      "  [/VBD\n",
      "  13/CD\n",
      "  ]/NNP\n",
      "  Scientific/NNP\n",
      "  reviews/VBZ\n",
      "  state/NN\n",
      "  that/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  outdated/JJ\n",
      "  metaphors/NNS\n",
      "  of/IN\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  brain/NN\n",
      "  works/VBZ\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  inconsistent/JJ\n",
      "  with/IN\n",
      "  current/JJ\n",
      "  neurological/JJ\n",
      "  theory/NN\n",
      "  and/CC\n",
      "  contain/VBP\n",
      "  numerous/JJ\n",
      "  factual/JJ\n",
      "  errors/NNS\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  11/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  12/CD\n",
      "  ]/NNP\n",
      "  [/VBD\n",
      "  13/CD\n",
      "  ]/NNP\n",
      "  Scientific/NNP\n",
      "  reviews/VBZ\n",
      "  state/NN\n",
      "  that/IN\n",
      "  (NE NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  outdated/JJ\n",
      "  metaphors/NNS\n",
      "  of/IN\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  brain/NN\n",
      "  works/VBZ\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  inconsistent/JJ\n",
      "  with/IN\n",
      "  current/JJ\n",
      "  neurological/JJ\n",
      "  theory/NN\n",
      "  and/CC\n",
      "  contain/VBP\n",
      "  numerous/JJ\n",
      "  factual/JJ\n",
      "  errors/NNS\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  10/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  14/CD\n",
      "  ]/NNP\n",
      "  (PERSON Reviews/NNP)\n",
      "  also/RB\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  supportive/JJ\n",
      "  research/NN\n",
      "  on/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  contained/VBD\n",
      "  significant/JJ\n",
      "  methodological/JJ\n",
      "  flaws/NNS\n",
      "  and/CC\n",
      "  that/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  three/CD\n",
      "  times/NNS\n",
      "  as/IN\n",
      "  many/JJ\n",
      "  studies/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  much/JJ\n",
      "  higher/JJR\n",
      "  quality/NN\n",
      "  that/WDT\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  extraordinary/JJ\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (PERSON Bandler/NNP)\n",
      "  ,/,\n",
      "  (PERSON Grinder/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  practitioners/NNS\n",
      "  ./.)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S\n",
      "  [/RB\n",
      "  10/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  14/CD\n",
      "  ]/NNP\n",
      "  Reviews/NNP\n",
      "  also/RB\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  supportive/JJ\n",
      "  research/NN\n",
      "  on/IN\n",
      "  (NE NLP/NNP)\n",
      "  contained/VBD\n",
      "  significant/JJ\n",
      "  methodological/JJ\n",
      "  flaws/NNS\n",
      "  and/CC\n",
      "  that/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  three/CD\n",
      "  times/NNS\n",
      "  as/IN\n",
      "  many/JJ\n",
      "  studies/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  much/JJ\n",
      "  higher/JJR\n",
      "  quality/NN\n",
      "  that/WDT\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  extraordinary/JJ\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (NE Bandler/NNP)\n",
      "  ,/,\n",
      "  (NE Grinder/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  NLP/NNP\n",
      "  practitioners/NNS\n",
      "  ./.)\n",
      "Without Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S [/RB 12/CD ]/JJ [/$ 13/CD ]/NN)\n",
      "----------------------------------------------------------------------------------\n",
      "With Binary NER\n",
      "-----------------------------------------------------------------------------------\n",
      "(S [/RB 12/CD ]/JJ [/$ 13/CD ]/NN)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            print('Without Binary NER')\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            # Try without apply binary=True\n",
    "            namedEntity = nltk.ne_chunk(tagged)\n",
    "            #namedEntity.draw()\n",
    "            print(namedEntity)\n",
    "            print('----------------------------------------------------------------------------------')\n",
    "            \n",
    "            print('With Binary NER')\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            # try with apply binary= True\n",
    "            namedEntity_Bin = nltk.ne_chunk(tagged,binary=True)\n",
    "            print(namedEntity_Bin)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "print(\"Go and watch the output like name entity recognition e.g., organization(NNP/NN),....\")\n",
    "print('')\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0030ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMMATIZATION IT IS SIMILAR TO STEMMING BUT A BIT BETTER THAN STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa0aebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b137dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "dog\n",
      "corpus\n",
      "goose\n",
      "rock\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"dogs\"))\n",
    "print(lemmatizer.lemmatize(\"corpora\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d075e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General_lemma: worst\n",
      "Adjective_change_lemma -> worst to : bad\n",
      "Adjective_change_lemma -> better to: good\n",
      "lemma_v: run\n",
      "lemma_verb_initiated: run\n"
     ]
    }
   ],
   "source": [
    "# different approach based on noun,adjective,verb\n",
    "\n",
    "#general\n",
    "print('General_lemma:',lemmatizer.lemmatize(\"worst\"))\n",
    "\n",
    "# Adjective\n",
    "print('Adjective_change_lemma -> worst to :',lemmatizer.lemmatize(\"worst\", pos='a'))\n",
    "print('Adjective_change_lemma -> better to:',lemmatizer.lemmatize(\"better\",pos='a'))\n",
    "\n",
    "#verb\n",
    "print('lemma_v:',lemmatizer.lemmatize(\"run\"))\n",
    "print('lemma_verb_initiated:',lemmatizer.lemmatize(\"run\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e3ac0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORPUS - IT IS A INBUILD DATA OF TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f06174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "715f0240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--HACKLUYT\\r\\n\\r\\n\"WHALE.', '... Sw. and Dan.', 'HVAL.', 'This animal is named from roundness\\r\\nor rolling; for in Dan.', 'HVALT is arched or vaulted.\"', '--WEBSTER\\'S\\r\\nDICTIONARY\\r\\n\\r\\n\"WHALE.', '...', 'It is more immediately from the Dut.', 'and Ger.', 'WALLEN;\\r\\nA.S. WALW-IAN, to roll, to wallow.\"']\n"
     ]
    }
   ],
   "source": [
    "sample = gutenberg.raw(\"melville-moby_dick.txt\")\n",
    "tok = sent_tokenize(sample)\n",
    "print(tok[5:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baf52a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c8ba359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5ec54fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ingredients', ':', 'london', 'gal', ',', 'fate', ',', 'true', 'love', ',', 'running', 'joke', 'about', 'monty', 'python', \"'\", 's', 'spanish', 'inquisition', 'synopsis', ':', 'american', 'actress', 'gwyneth', 'paltrow', 'with', 'dark', 'hair', ',', 'playing', 'a', 'londoner', '?', 'believe', 'it', '.', 'sliding', 'doors', 'is', 'a', 'love', \"'\", 'what', 'if', \"'\", 'story', '.', 'the', 'gimmick', 'is', 'that', 'it', \"'\", 's', 'really', 'two', 'stories', ':', 'the', 'film', 'follows', 'the', 'life', 'of', 'helen', '(', 'gwyneth', 'paltrow', ')', 'down', 'two', 'directions', '.', 'in', 'the', 'beginning', ',', 'likeable', 'gal', \"'\", 'helen', \"'\", '(', 'gwyneth', 'paltrow', ')', 'gets', 'unexpectedly', 'fired', 'from', 'her', 'advertising', 'job', '.', 'so', 'she', 'goes', 'into', 'the', 'subway', 'train', 'station', 'meaning', 'to', 'return', 'home', 'early', 'to', 'her', 'apartment', 'and', 'her', 'sleeping', 'live', '-', 'in', 'lover', 'gerry', '(', 'john', 'lynch', ')', '.', 'helen', 'doesn', \"'\", 't', 'know', 'it', ',', 'but', 'she', 'is', 'at', 'a', 'fateful', 'junction', 'in', 'life', ':', '1', ')', 'if', 'she', 'enters', 'through', 'the', 'sliding', 'door', 'of', 'a', 'london', 'subway', 'train', 'her', 'life', 'takes', 'one', 'path', 'with', 'one', 'future', '2', ')', 'if', 'she', 'stays', 'on', 'the', 'platform', 'her', 'life', 'takes', 'another', 'path', 'with', 'a', 'different', 'future', '.', 'the', 'film', 'shows', 'what', 'happens', 'in', 'both', 'paths', ',', 'switching', 'back', 'and', 'forth', 'between', 'intertwined', ',', 'parallel', 'stories', '.', 'in', 'story', 'one', ',', 'helen', 'meets', 'a', 'charming', 'and', 'talkative', 'monty', 'python', 'fan', 'named', 'james', '(', 'john', 'hannah', ')', 'on', 'the', 'train', '.', 'arriving', 'home', 'early', ',', 'she', 'discovers', 'that', 'her', 'live', '-', 'in', ',', 'gerry', '(', 'john', 'lynch', ')', ',', 'is', 'having', 'sex', 'with', 'his', 'former', 'lover', 'lydia', '(', 'jeanne', 'tripplehorn', ')', '.', 'this', 'leads', 'to', 'a', 'life', 'where', 'helen', 'moves', 'out', '.', 'helen', \"'\", 's', 'winsome', 'new', 'friend', 'james', 'helps', 'her', 'recover', 'from', 'a', 'broken', 'heart', ',', 'and', 'encourages', 'her', 'to', 'start', 'her', 'own', 'business', '.', 'in', 'story', 'two', ',', 'helen', 'experiences', 'a', 'different', 'fate', '.', 'she', 'misses', 'the', 'train', ',', 'never', 'meets', 'james', ',', 'and', 'doesn', \"'\", 't', 'get', 'home', 'early', 'enough', 'to', 'discover', 'gerry', \"'\", 's', 'infidelity', '.', 'in', 'this', 'new', 'life', ',', 'helen', 'takes', 'up', 'odd', 'menial', 'jobs', ',', 'and', 'faces', 'the', 'constant', 'sneaking', 'suspicion', 'that', 'all', 'is', 'not', 'right', 'with', 'her', 'relationship', 'with', 'gerry', '.', 'will', 'the', 'truth', 'of', 'the', 'heart', 'finally', 'work', 'its', 'way', 'through', 'a', 'number', 'of', 'problems', 'and', 'setbacks', 'in', 'both', 'scenarios', '?', 'opinion', ':', 'rejoice', 'all', 'ye', 'monty', 'python', 'fans', ',', 'gwyneth', 'paltrow', 'fans', ',', 'and', 'watchers', 'of', 'quirky', 'romance', 'flicks', '.', 'at', 'last', 'here', \"'\", 's', 'proof', 'that', 'there', \"'\", 's', 'still', 'creativity', 'in', '1990s', 'filmmaking', '.', 'sliding', 'doors', 'is', 'refreshingly', 'different', 'from', 'anything', 'this', 'year', '.', 'not', 'only', 'is', 'it', 'a', 'well', '-', 'acted', ',', 'heartwarming', 'film', ',', 'but', 'it', \"'\", 's', 'also', 'easily', 'gwyneth', 'paltrow', \"'\", 's', 'best', 'recent', 'performance', '.', 'when', 'helen', '(', 'paltrow', ')', 'screams', 'that', 'her', 'unfaithful', 'boyfriend', 'is', 'a', \"'\", 'shagging', 'wanker', ',', \"'\", '(', 'a', 'british', 'phrase', 'better', 'left', 'untranslated', ')', 'she', 'sounds', 'like', 'she', 'knows', 'what', 'she', \"'\", 's', 'talking', 'about', '!', 'nor', 'does', 'sliding', 'doors', 'go', 'overboard', 'with', 'formulaic', 'true', 'love', 'or', 'other', 'stereotypes', '.', 'nobody', 'scrambles', 'around', 'in', 'danger', ',', 'screaming', ',', '\"', 'i', 'will', 'find', 'you', 'no', 'matter', 'what', ',', 'my', 'darling', '!', '\"', 'when', 'helen', 'finds', 'herself', 'on', 'a', 'boat', 'in', 'the', 'starlight', 'with', 'james', ',', 'she', 'doesn', \"'\", 't', 'take', 'the', 'easy', 'way', 'out', 'and', 'leap', 'into', 'his', 'arms', ',', 'since', 'she', \"'\", 's', 'supposed', 'to', 'be', 'recovering', 'from', 'heartache', '.', 'and', 'handsome', 'live', '-', 'in', 'boyfriend', 'gerry', 'isn', \"'\", 't', 'the', 'stereotypical', 'screen', 'hunk', '(', 'either', 'a', 'stud', 'or', 'a', 'snob', ')', '.', 'instead', 'he', \"'\", 's', 'a', 'nervous', 'and', 'indecisive', ',', 'almost', 'helpless', 'hunk', '.', 'another', 'example', ':', 'when', 'one', 'of', 'the', 'protagonists', 'lies', 'wounded', 'in', 'a', 'hospital', ',', 'sliding', 'doors', 'gives', 'us', 'neither', 'the', \"'\", 'hospital', 'miracle', \"'\", 'nor', 'a', 'maudlin', 'tragedy', 'but', 'surprises', 'us', 'with', 'a', 'third', 'variation', '.', 'in', 'other', 'words', ',', 'all', 'of', 'the', 'characters', 'seem', 'non', '-', 'stereotyped', ',', 'human', ',', 'and', 'local', '.', 'there', 'are', 'minor', 'inconveniences', '.', 'since', 'sliding', 'doors', 'switches', 'back', 'and', 'forth', 'between', 'two', 'possible', 'fates', ',', 'it', \"'\", 's', 'occasionally', 'difficult', 'to', 'distinguish', 'between', 'the', 'two', '.', 'distinguishing', 'between', 'the', 'two', 'stories', 'isn', \"'\", 't', 'a', 'problem', 'in', 'the', 'scenes', 'containing', 'paltrow', ',', 'who', 'sports', 'two', 'different', 'hairstyles', '.', 'but', 'in', 'scenes', 'containing', 'only', 'lydia', 'and', 'gerry', ',', 'who', 'look', 'the', 'same', 'in', 'both', 'stories', ',', 'it', \"'\", 's', 'slightly', 'confusing', '.', 'also', ',', 'quite', 'a', 'few', 'snappy', 'comebacks', 'referring', 'to', 'american', 'pop', 'culture', '(', 'seinfeld', ',', 'woody', 'allen', ',', 'etc', '.', ')', 'are', 'spoken', 'by', 'the', 'british', 'characters', '.', 'but', 'these', 'seem', 'slightly', 'forced', ',', 'given', 'that', 'the', 'remaining', 'dialogue', 'is', 'predominantly', 'british', 'slang', '.', 'possibly', 'an', 'attempt', 'by', 'the', 'screenwriter', 'to', 'balance', 'the', 'british', 'so', 'that', 'american', 'audiences', 'can', 'feel', 'more', 'comfortable', '?', 'sliding', 'doors', 'is', 'a', 'charming', ',', 'quirky', ',', 'original', ',', 'happy', 'romance', 'with', 'a', 'little', \"'\", 'philosophy', 'of', 'fate', \"'\", 'thrown', 'in', '.', 'monty', 'python', 'and', 'the', 'meaning', 'of', 'fate', ',', 'anybody', '?'], 'pos')\n"
     ]
    }
   ],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)),category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ede9803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "# Print Most common words in the movie reviews (15) - How many time used\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96f0b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many time word \"happy\" comes in movie reviews:  215\n"
     ]
    }
   ],
   "source": [
    "print('How many time word \"happy\" comes in movie reviews: ',all_words[\"happy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a7348de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f11eefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab34a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our corpus:  ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n",
      "BoW representation for 'man bites dog:  [[1 1 0 0 1 0]]\n",
      "Bow representation for 'dog bites are friends': [[0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#Now, let's do the main task of finding bag of words representation. We will use CountVectorizer from sklearn.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#look at the documents list\n",
    "print(\"Our corpus: \", processed_docs)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and man are friends\"])\n",
    "print(\"Bow representation for 'dog bites are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3463900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow representation for 'dog bites man are friends': [[0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#In the above code, we represented the text considering the frequency of words into account. However, sometimes, we don't care about frequency much, but only want to know whether a word appeared in a text or not. That is, each document is represented as a vector of 0s and 1s. We will use the option binary=True in CountVectorizer for this purpose.\n",
    "#BoW with binary vectors\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "count_vect.fit(processed_docs)\n",
    "temp = count_vect.transform([\"dog man are friends\"])\n",
    "print(\"Bow representation for 'dog bites man are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b9fea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG OF N-GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19237d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:  {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n",
      "BoW representation for 'dog bites man':  [[1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "BoW representation for 'man bites dog:  [[1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())\n",
    "\n",
    "#Note that the number of features (and hence the size of the feature vector) increased a lot for the same \n",
    "#data, compared to the ther single word based representations!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d69bc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f228c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_docs: ['vk hit bat', 'vk ran street', 'dog eats carrot', 'vk dog love very much in vk']\n",
      "-----------------------------------------------------\n",
      "\n",
      "IDF for all words in the vocabulary [1.91629073 1.91629073 1.51082562 1.91629073 1.91629073 1.91629073\n",
      " 1.91629073 1.91629073 1.91629073 1.91629073 1.91629073 1.22314355]\n",
      "----------\n",
      "All words in the vocabulary ['bat' 'carrot' 'dog' 'eats' 'hit' 'in' 'love' 'much' 'ran' 'street'\n",
      " 'very' 'vk']\n",
      "----------\n",
      "TFIDF representation for all documents in our corpus\n",
      " [[0.64450299 0.         0.         0.         0.64450299 0.\n",
      "  0.         0.         0.         0.         0.         0.41137791]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.64450299 0.64450299 0.         0.41137791]\n",
      " [0.         0.61761437 0.48693426 0.61761437 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.31533346 0.         0.         0.39996052\n",
      "  0.39996052 0.39996052 0.         0.         0.39996052 0.51057923]]\n",
      "----------\n",
      "Tfidf representation for 'dog and vk are friends':\n",
      " [[0.         0.         0.77722116 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.62922751]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"vk hit bat.\", \"vk ran street.\", \"Dog eats carrot.\", \"vk dog love very much in vk.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "print(\"processed_docs:\",processed_docs)\n",
    "print('-----------------------------------------------------')\n",
    "print('')\n",
    "#Initialize the TFIDF\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "#IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
    "print(\"-\"*10)\n",
    "#All words in the vocabulary.\n",
    "print(\"All words in the vocabulary\",tfidf.get_feature_names_out())\n",
    "print(\"-\"*10)\n",
    "\n",
    "#TFIDF representation for all documents in our corpus \n",
    "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray()) \n",
    "print(\"-\"*10)\n",
    "\n",
    "temp = tfidf.transform([\"vk and dog are friends\"])\n",
    "print(\"Tfidf representation for 'dog and vk are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd933132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0f59679",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['vk','birds','dog','bites','man'], [\"man\", \"bites\" ,\"dog\",\"love\"],[\"dog\",\"eats\",\"meat\",\"cat\"],[\"man\", \"eats\",\"food\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d25043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the loaded model\n",
    "print(model_cbow)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(model_cbow.wv.vocab) # continuous bag of words\n",
    "print(words)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(model_cbow['dog'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
